# Part 6 – Correlation Recommendations, Percentages, and Optimization Logic

> **Purpose of this part**  
This chapter explains correlation *metrics*, *recommendations*, and *optimization* without turning them into blind automation.
The goal is to use numbers as **signals**, not as decision-makers.

By the end of this part, you should:
- understand what correlation percentages actually measure
- know how recommendations are generated
- use optimization safely without damaging identity truth
- avoid designing correlation to satisfy metrics instead of reality

---

## 6.1 Metrics are feedback, not goals

Correlation metrics answer one question:

> “How many accounts matched using a given rule?”

They do **not** answer:
- whether the match was correct
- whether the rule is safe
- whether ownership is trustworthy

High percentage does not equal high quality.

---

## 6.2 What correlation percentage really represents

When ISC shows a correlation percentage, it means:

- number of accounts that matched this rule
- divided by total evaluated accounts
- at the moment the analysis ran

It does not validate:
- uniqueness
- correctness
- long-term stability

Percentages measure *volume*, not *truth*.

---

## 6.3 How recommendations are generated

Correlation recommendations are generated by analyzing:

- existing identity attribute values
- incoming account attribute values
- match frequency between them

The system suggests:
- attribute pairings
- estimated match percentages
- potential ordering

This is statistical analysis, not business logic.

---

## 6.4 Why recommendations can be misleading

A recommendation can look attractive because:

- it has a high match rate
- it reduces uncorrelated count
- it looks “clean” in dashboards

But it may be risky because:
- values are not unique
- values change over time
- matches are coincidental

Recommendations do not understand identity lifecycle.

---

## 6.5 Optimization logic explained simply

Optimization attempts to:

> “Move rules with higher match rates earlier in the order.”

This improves efficiency and coverage.
It does not improve correctness.

Optimization assumes:
- higher match rate equals better rule
- matches are equally trustworthy

These assumptions are often false.

---

## 6.6 When optimization helps

Optimization can be helpful when:

- identifiers are truly unique
- lifecycle is mature and stable
- data quality is high
- authoritative source is clean

In these cases, reordering may reduce processing effort without increasing risk.

---

## 6.7 When optimization causes harm

Optimization is dangerous when:

- email is used as an identifier
- contractors reuse identifiers
- attributes change mid-lifecycle
- multiple identities share values

In these cases, optimization:
- prioritizes risky rules
- increases false correlation
- hides ownership issues

Silent damage is the worst outcome.

---

## 6.8 A safe way to use recommendations

Use recommendations as **questions**, not answers.

Ask:
- why does this rule match so many accounts?
- is this value guaranteed unique?
- what happens when it changes?
- would I defend this in an audit?

If you cannot explain it confidently, do not use it.

---

## 6.9 Never design for percentage reduction

A common anti-pattern:

> “We need to reduce uncorrelated accounts from 20% to 5%.”

This mindset encourages:
- weak identifiers
- forced correlation
- audit risk

The goal is **correct ownership**, not coverage.

---

## 6.10 A healthy metric mindset

Good correlation health looks like:
- predictable uncorrelated accounts
- explainable exceptions
- stable ownership over time
- trust in reports

This often includes some uncorrelated accounts.

---

## 6.11 Real-world example

Optimization suggests:
- email first (85% match)
- employeeId second (60% match)

Design choice:
- employeeId stays first
- email remains fallback

Result:
- slightly higher uncorrelated count
- much higher trust in ownership

Metrics went down.
Quality went up.

---

## 6.12 How to review optimization safely

Before accepting optimization:
1. review uniqueness guarantees
2. review lifecycle timing
3. review authoritative impact
4. test in non-production
5. observe before committing

Never optimize directly in production without validation.

---

## 6.13 What this part prepares you for

After this part, you should:
- stop chasing percentages
- treat recommendations as guidance, not commands
- design correlation you can defend

Next, we move into **custom identity attributes and searchability**, where many teams get blocked.

---

## Navigation

**⬅ Back:** Part 5 – Uncorrelated Accounts Resolution and Safe Fixes  
**➡ Next:** Part 7 – Custom Identity Attributes and Searchability

---

*End of Part 6*
